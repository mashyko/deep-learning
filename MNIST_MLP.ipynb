{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the MNIST dataset:\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "MNISTデータセットはY. LeCunのWebサイトで公開されています。MNISTデータセットは<br>\n",
    "トレーニングデータセットの画像：train-images-idx3-ubyte.gz <br>\n",
    "トレーニングデータセットのラベル：train-labels-idx1-ubyte.gz <br>\n",
    "テストデータセットの画像：test-images-idx3-ubyte.gz <br>\n",
    "テストデータセットのラベル：test-labels-idx1-ubyte.gz <br>\n",
    "の4種類から構成されています。上記のwebサイトからダウンロードしてください。working directoryに移動、保存してください。これらのファイルは、gzipで解凍する必要があります。\n",
    "$ cd (working derectory)\n",
    "$ gzip *ubyte.gz -d\n",
    "とします。\n",
    "以下のようなPythonコードを実行するとデータが読み込まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', \n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, \n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", \n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, \n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('./',kind='train')\n",
    "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_mnist('./', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first digit of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1513632da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/mnist_all.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_output : int\n",
    "        Number of output units, should be equal to the\n",
    "        number of unique class labels.\n",
    "    n_features : int\n",
    "        Number of features (dimensions) in the target dataset.\n",
    "        Should be equal to the number of columns in the X array.\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units.\n",
    "    l1 : float (default: 0.0)\n",
    "        Lambda value for L1-regularization.\n",
    "        No regularization if l1=0.0 (default)\n",
    "    l2 : float (default: 0.0)\n",
    "        Lambda value for L2-regularization.\n",
    "        No regularization if l2=0.0 (default)\n",
    "    epochs : int (default: 500)\n",
    "        Number of passes over the training set.\n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate.\n",
    "    alpha : float (default: 0.0)\n",
    "        Momentum constant. Factor multiplied with the\n",
    "        gradient of the previous epoch t-1 to improve\n",
    "        learning speed\n",
    "        w(t) := w(t) - (grad(t) + alpha*grad(t-1))\n",
    "    decrease_const : float (default: 0.0)\n",
    "        Decrease constant. Shrinks the learning rate\n",
    "        after each epoch via eta / (1 + epoch*decrease_const)\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent circles.\n",
    "    minibatches : int (default: 1)\n",
    "        Divides training data into k minibatches for efficiency.\n",
    "        Normal gradient descent learning if k=1 (default).\n",
    "    random_state : int (default: None)\n",
    "        Set random state for shuffling and initializing the weights.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    cost_ : list\n",
    "      Sum of squared errors after each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_output, n_features, n_hidden=30,\n",
    "                 l1=0.0, l2=0.0, epochs=500, eta=0.001,\n",
    "                 alpha=0.0, decrease_const=0.0, shuffle=True,\n",
    "                 minibatches=1, random_state=None):\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "        self.n_output = n_output\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.w1, self.w2 = self._initialize_weights()\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "\n",
    "    def _encode_labels(self, y, k):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_labels, n_samples)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((k, y.shape[0]))\n",
    "        for idx, val in enumerate(y):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        w1 = np.random.uniform(-1.0, 1.0,\n",
    "                               size=self.n_hidden*(self.n_features + 1))\n",
    "        w1 = w1.reshape(self.n_hidden, self.n_features + 1)\n",
    "        w2 = np.random.uniform(-1.0, 1.0,\n",
    "                               size=self.n_output*(self.n_hidden + 1))\n",
    "        w2 = w2.reshape(self.n_output, self.n_hidden + 1)\n",
    "        return w1, w2\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\n",
    "\n",
    "        Uses scipy.special.expit to avoid overflow\n",
    "        error for very small input values z.\n",
    "\n",
    "        \"\"\"\n",
    "        # return 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "\n",
    "    def _sigmoid_gradient(self, z):\n",
    "        \"\"\"Compute gradient of the logistic function\"\"\"\n",
    "        sg = self._sigmoid(z)\n",
    "        return sg * (1.0 - sg)\n",
    "\n",
    "    def _add_bias_unit(self, X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            X_new = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "            X_new[:, 1:] = X\n",
    "        elif how == 'row':\n",
    "            X_new = np.ones((X.shape[0] + 1, X.shape[1]))\n",
    "            X_new[1:, :] = X\n",
    "        else:\n",
    "            raise AttributeError('`how` must be `column` or `row`')\n",
    "        return X_new\n",
    "\n",
    "    def _feedforward(self, X, w1, w2):\n",
    "        \"\"\"Compute feedforward step\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "            Weight matrix for input layer -> hidden layer.\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "            Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        a1 : array, shape = [n_samples, n_features+1]\n",
    "            Input values with bias unit.\n",
    "        z2 : array, shape = [n_hidden, n_samples]\n",
    "            Net input of hidden layer.\n",
    "        a2 : array, shape = [n_hidden+1, n_samples]\n",
    "            Activation of hidden layer.\n",
    "        z3 : array, shape = [n_output_units, n_samples]\n",
    "            Net input of output layer.\n",
    "        a3 : array, shape = [n_output_units, n_samples]\n",
    "            Activation of output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        a1 = self._add_bias_unit(X, how='column')\n",
    "        z2 = w1.dot(a1.T)\n",
    "        a2 = self._sigmoid(z2)\n",
    "        a2 = self._add_bias_unit(a2, how='row')\n",
    "        z3 = w2.dot(a2)\n",
    "        a3 = self._sigmoid(z3)\n",
    "        return a1, z2, a2, z3, a3\n",
    "\n",
    "    def _L2_reg(self, lambda_, w1, w2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        return (lambda_/2.0) * (np.sum(w1[:, 1:] ** 2) +\n",
    "                                np.sum(w2[:, 1:] ** 2))\n",
    "\n",
    "    def _L1_reg(self, lambda_, w1, w2):\n",
    "        \"\"\"Compute L1-regularization cost\"\"\"\n",
    "        return (lambda_/2.0) * (np.abs(w1[:, 1:]).sum() +\n",
    "                                np.abs(w2[:, 1:]).sum())\n",
    "\n",
    "    def _get_cost(self, y_enc, output, w1, w2):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_labels, n_samples)\n",
    "            one-hot encoded class labels.\n",
    "        output : array, shape = [n_output_units, n_samples]\n",
    "            Activation of the output layer (feedforward)\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "            Weight matrix for input layer -> hidden layer.\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "            Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "            Regularized cost.\n",
    "\n",
    "        \"\"\"\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1.0 - y_enc) * np.log(1.0 - output)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        L1_term = self._L1_reg(self.l1, w1, w2)\n",
    "        L2_term = self._L2_reg(self.l2, w1, w2)\n",
    "        cost = cost + L1_term + L2_term\n",
    "        return cost\n",
    "\n",
    "    def _get_gradient(self, a1, a2, a3, z2, y_enc, w1, w2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        a1 : array, shape = [n_samples, n_features+1]\n",
    "            Input values with bias unit.\n",
    "        a2 : array, shape = [n_hidden+1, n_samples]\n",
    "            Activation of hidden layer.\n",
    "        a3 : array, shape = [n_output_units, n_samples]\n",
    "            Activation of output layer.\n",
    "        z2 : array, shape = [n_hidden, n_samples]\n",
    "            Net input of hidden layer.\n",
    "        y_enc : array, shape = (n_labels, n_samples)\n",
    "            one-hot encoded class labels.\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "            Weight matrix for input layer -> hidden layer.\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "            Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        grad1 : array, shape = [n_hidden_units, n_features]\n",
    "            Gradient of the weight matrix w1.\n",
    "        grad2 : array, shape = [n_output_units, n_hidden_units]\n",
    "            Gradient of the weight matrix w2.\n",
    "\n",
    "        \"\"\"\n",
    "        # backpropagation\n",
    "        sigma3 = a3 - y_enc\n",
    "        z2 = self._add_bias_unit(z2, how='row')\n",
    "        sigma2 = w2.T.dot(sigma3) * self._sigmoid_gradient(z2)\n",
    "        sigma2 = sigma2[1:, :]\n",
    "        grad1 = sigma2.dot(a1)\n",
    "        grad2 = sigma3.dot(a2.T)\n",
    "\n",
    "        # regularize\n",
    "        grad1[:, 1:] += self.l2 * w1[:, 1:]\n",
    "        grad1[:, 1:] += self.l1 * np.sign(w1[:, 1:])\n",
    "        grad2[:, 1:] += self.l2 * w2[:, 1:]\n",
    "        grad2[:, 1:] += self.l1 * np.sign(w2[:, 1:])\n",
    "\n",
    "        return grad1, grad2\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(X.shape) != 2:\n",
    "            raise AttributeError('X must be a [n_samples, n_features] array.\\n'\n",
    "                                 'Use X[:,None] for 1-feature classification,'\n",
    "                                 '\\nor X[[i]] for 1-sample classification')\n",
    "\n",
    "        a1, z2, a2, z3, a3 = self._feedforward(X, self.w1, self.w2)\n",
    "        y_pred = np.argmax(z3, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features.\n",
    "        y : array, shape = [n_samples]\n",
    "            Target class labels.\n",
    "        print_progress : bool (default: False)\n",
    "            Prints progress as the number of epochs\n",
    "            to stderr.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        self.cost_ = []\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        y_enc = self._encode_labels(y, self.n_output)\n",
    "\n",
    "        delta_w1_prev = np.zeros(self.w1.shape)\n",
    "        delta_w2_prev = np.zeros(self.w2.shape)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx = np.random.permutation(y_data.shape[0])\n",
    "                X_data, y_enc = X_data[idx], y_enc[:, idx]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                a1, z2, a2, z3, a3 = self._feedforward(X_data[idx],\n",
    "                                                       self.w1,\n",
    "                                                       self.w2)\n",
    "                cost = self._get_cost(y_enc=y_enc[:, idx],\n",
    "                                      output=a3,\n",
    "                                      w1=self.w1,\n",
    "                                      w2=self.w2)\n",
    "                self.cost_.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(a1=a1, a2=a2,\n",
    "                                                  a3=a3, z2=z2,\n",
    "                                                  y_enc=y_enc[:, idx],\n",
    "                                                  w1=self.w1,\n",
    "                                                  w2=self.w2)\n",
    "\n",
    "                delta_w1, delta_w2 = self.eta * grad1, self.eta * grad2\n",
    "                self.w1 -= (delta_w1 + (self.alpha * delta_w1_prev))\n",
    "                self.w2 -= (delta_w2 + (self.alpha * delta_w2_prev))\n",
    "                delta_w1_prev, delta_w2_prev = delta_w1, delta_w2\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_output=10, \n",
    "                  n_features=X_train.shape[1], \n",
    "                  n_hidden=50, \n",
    "                  l2=0.1, \n",
    "                  l1=0.0, \n",
    "                  epochs=800, \n",
    "                  eta=0.001,\n",
    "                  alpha=0.001,\n",
    "                  decrease_const=0.00001,\n",
    "                  minibatches=50, \n",
    "                  shuffle=True,\n",
    "                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1000/1000"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x1053cd518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, print_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the decreases in cost per epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVghDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1070a8630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = np.array_split(range(len(nn.cost_)), 1000)\n",
    "cost_ary = np.array(nn.cost_)\n",
    "cost_avgs = [np.mean(cost_ary[i]) for i in batches]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylim([0, 2000])\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./figures/cost2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "showing the training and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.59%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = nn.predict(X_train)\n",
    "\n",
    "if sys.version_info < (3, 0):\n",
    "    acc = ((np.sum(y_train == y_train_pred, axis=0)).astype('float') /\n",
    "           X_train.shape[0])\n",
    "else:\n",
    "    acc = np.sum(y_train == y_train_pred, axis=0) / X_train.shape[0]\n",
    "\n",
    "print('Training accuracy: %.2f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.66%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = nn.predict(X_test)\n",
    "\n",
    "if sys.version_info < (3, 0):\n",
    "    acc = ((np.sum(y_test == y_test_pred, axis=0)).astype('float') /\n",
    "           X_test.shape[0])\n",
    "else:\n",
    "    acc = np.sum(y_test == y_test_pred, axis=0) / X_test.shape[0]\n",
    "\n",
    "print('Test accuracy: %.2f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
